Causal Representation Learning with Generative Artificial
Intelligence: Application to Texts as Treatments*
Kosuke Imai† Kentaro Nakamura‡
September 9, 2025
Abstract
In this paper, we demonstrate how to enhance the validity of causal inference with unstructured highdimensional treatments like texts, by leveraging the power of generative Artificial Intelligence (GenAI).
Specifically, we propose to use a deep generative model such as large language models (LLMs) to efficiently generate treatments and use their internal representation for subsequent causal effect estimation.
We show that the knowledge of this true internal representation helps disentangle the treatment features
of interest, such as specific sentiments and certain topics, from other possibly unknown confounding
features. Unlike existing methods, the proposed GenAI-Powered Inference (GPI) methodology eliminates the need to learn causal representation from the data, and hence produces more accurate and
efficient estimates. We formally establish the conditions required for the nonparametric identification
of the average treatment effect, propose an estimation strategy that avoids the violation of the overlap
assumption, and derive the asymptotic properties of the proposed estimator through the application of
double machine learning. Finally, using an instrumental variables approach, we extend the proposed
GPI methodology to the settings in which the treatment feature is based on human perception. The GPI
is also applicable to text reuse where an LLM is used to regenerate existing texts. We conduct simulation
and empirical studies, using the generated text data from an open-source LLM, Llama 3, to illustrate the
advantages of our estimator over state-of-the-art causal representation learning algorithms.
Key Words: causal inference, deep generative models, double machine learning, large language models,
unstructured treatments
*An open-source Python package, “GPI: Generative-AI Powered Inference,” that implements the proposed methodology is
available at https://gpi-pack.github.io/. The replication code and data are available at https://github.com/
k-nakam/gpi_replication. We thank Christian Fong and Justin Grimmer for kindly sharing their dataset used in Candidate
Profile Experiment and Naoki Egami for helpful comments. We also acknowledge useful comments from Naoki Egami, Max Kasy,
and an anonymous reviewer of Harvard’s Alexander and Diviya Magaro Peer Pre-Review Program.
†
Professor, Department of Government and Department of Statistics, Harvard University, Cambridge, MA 02138. Phone:
617–384–6778, Email: Imai@Harvard.Edu, URL: https://imai.fas.harvard.edu
‡
Ph.D. student, John F. Kennedy School of Government, Harvard University. Email: knakamura@g.harvard.edu
arXiv:2410.00903v4 [stat.AP] 6 Sep 2025
1 Introduction
The emergence of generative artificial intelligence (GenAI) technology such as large language models
(LLMs) has had an enormous impact on many fields, including medicine (Thirunavukarasu et al., 2023),
education (Kasneci et al., 2023), marketing (Kshetri et al., 2024), and social sciences (Bisbee et al., 2024).
These tools come with advanced capabilities to generate realistic texts, images, and videos at scale, based
on the user-provided prompts.
In this paper, we demonstrate that GenAI can enhance the performance of causal representation learning
from unstructured data such as text and images. We focus on the problem of estimating the causal effect
of a specific treatment feature embedded in text—such as topic or sentiment—while adjusting for other
confounding features. Although we assume the treatment feature is pre-specified and measurable, the central challenge lies in learning a low-dimensional representation of the unknown confounders and properly
adjusting for them. We show that internal representations extracted from GenAI models can be leveraged
within a causal machine learning framework to estimate the causal effects of interest. Specifically, we introduce an experimental design (Section 2) and propose the GenAI-Powered Inference (GPI) methodology
(Section 3), which enables efficient estimation of causal effects associated with specific features embedded
in unstructured data.
In the proposed experiment, we first generate texts by providing treatment and control prompts to an
LLM. If we wish to use existing texts rather than generate new ones, we ask an LLM to reproduce the same
texts exactly. We then present each generated text to a randomly selected survey respondent and measure
their reactions. Lastly, we directly extract the true internal representation of the generated text from the
LLM and analyze it with a machine learning algorithm to disentangle the treatment features from other
confounding features contained within the same texts. The GPI leverages the true vectorized representation
of treatment text that is available from an open-source deep generative model. This enables us to efficiently
learn causal representation of unstructured data even when texts contain strong confounding features.
We establish the nonparametric identification based on the key assumption of separability between
treatment and confounding features. This assumption states that the treatment feature is not a deterministic
function of confounding features and the latter are also not a function of the former. The assumption is
closely related to the concept of disentanglement in the literature (Wang and Jordan, 2024) and implies that
one can intervene the treatment feature without changing confounding features. We discuss diagnostic tools
to detect the potential violation of this assumption.
As part of the proposed estimation approach, we develop a neural network architecture based on TarNet (Shalit et al., 2017) to separately learn treatment and confounding features. We show that it is possible to nonparametrically identify a deconfounder, which summarizes all confounding features as a lowerdimensional function of the internal representation obtained from a deep generative model. Once a deconfounder is estimated, we use it to model the treatment features and estimate the propensity score. We then
apply the double machine learning (DML) methodology to obtain the asymptotically valid confidence intervals (Chernozhukov et al., 2018). An open-source Python package, “GPI: Generative-AI Powered Inference,” that implements the proposed methodology is available at https://gpi-pack.github.io/.
To investigate the empirical performance of the proposed methodology, we design simulation studies
based on the candidate profile experiment of Fong and Grimmer (2016) (Section 4). In this experiment,
survey respondents are asked to evaluate biographies of different political candidates. Our goal is to infer
the causal effects of certain features of these biographies, such as military background and education levels.
We use an open-source LLM, Llama 3, to generate a set of new candidate biographies and design simulation
studies to compare the performance of the proposed estimator with that of state-of-the-art methods. We also
have Llama 3 regenerate the existing biographies to examine the performance of the proposed methodology
in the case of text reuse.
We find that the GPI outperforms the state-of-the-art methods, which estimate the causal representation
2
using the existing embedding (Pryzant et al., 2021; Gui and Veitch, 2023). Specifically, the proposed estimator has a smaller bias and root mean squared error, while its confidence interval retains a proper nominal
coverage level. These findings hold even when the sample size is relatively small, and in the case of text
reuse. Furthermore, we apply the GPI to human responses to the candidate profile experiment (Section 5).
Our analysis shows that the previous military experience of the candidates significantly affects the voter
evaluation on average. Appendix S6 presents an additional empirical application based on experiments
about the public perceptions of US government support for Hong Kong protest (Fong and Grimmer, 2023).
We show that the GPI yields much more reasonable estimates than the existing state-of-the-art methods.
Imai and Nakamura (2025) presents additional applications of the GPI including one based on images.
Finally, we extend the GPI to the estimation of the causal effects of perceived treatment features, motivated by the fact that the respondents may perceive the same treatment features differently (Appendix S3).
A key challenge is that the perceived treatment features may be confounded by possibly unobserved respondent characteristics as well as the confounding features of texts. To address this, we adopt the instrumental
variable approach (Imbens and Angrist, 1994) by using the actual treatment features as instruments for their
perceived counterparts.
Related literature. Several existing works estimate the causal effects of textual features (see Feder et al.,
2022, for a review). The key difference between the GPI and these previous approaches is the use of GenAI
to produce treatment objects. We exploit the fact that the true vectorized representation of generated texts
can be obtained directly from open-source LLMs. In contrast, existing methods must learn causal representation from the treatment texts. For example, Fong and Grimmer (2016) and Ahrens et al. (2021) impose
topic models, whereas Pryzant et al. (2021) and Gui and Veitch (2023) estimate the vector representation
using the BERT (Bidirectional Encoder Representations from Transformers) embeddings. We show that
the use of true representation not only improves the estimation performance but also significantly increases
computational efficiency.
We advance the literature on causal inference with text by formalizing the assumptions necessary for
causal identification. Most prior studies implicitly assume that confounding features are not functions of
the treatment feature (e.g., Pryzant et al., 2021; Gui and Veitch, 2023), with the exception of Daoud et al.
(2022), who states this assumption explicitly. Consequently, no existing estimation method directly incorporates this assumption For instance, Fong and Grimmer (2023) recommends using topic models and adjusting
only for those estimated topics that are not functions of the treatment feature. In practice, however, reliably
identifying such topics is challenging, since any topic may be entangled with the treatment feature. Relatedly, the causal representation learning literature discusses this condition under the label of disentanglement
(Wang and Jordan, 2024), but does not consider interventions on the treatment feature while holding confounding features fixed. To address this gap, we introduce the separability assumption, which implies that
it be possible to intervene on the treatment feature without altering the confounding features.
Our work has broader implications for the literature on causal inference and unstructured objects in
general. For example, scholars have developed methods that adjust for texts as confounders, but all of these
methods estimate a low-dimensional representation of confounding information from texts (Veitch et al.,
2020; Roberts et al., 2020; Klaassen et al., 2024; Mozer et al., 2020, 2024). Although our paper focuses
on the use of texts as treatments rather than confounders, the proposed use of GenAI should be beneficial
for these other cases where existing estimation methods are likely to suffer from estimation error (Keith
et al., 2020). Similarly, the GPI can also be applied to causal inference problems with images and even
videos. For example, Jerzak et al. (2023a,b) have considered the use of causal inference with images in an
observational setting. Given the availability of deep generative models for images, it would be of interest to
use GenAI for improved causal inference with images (e.g., Ramesh et al., 2021; Rombach et al., 2022).
Our work contributes to the literature on causal representation learning. Since unstructured objects such
as texts are high-dimensional, learning a low-dimensional representation is crucial (e.g., Shi et al., 2019;
3
Wang and Jordan, 2024). Some propose learning a low-dimensional representation that predicts both treatment and outcome (e.g., Veitch et al., 2020; Gui and Veitch, 2023). Although we also use a low-dimensional
representation to adjust for confounding features, the GPI disentangles confounding features from treatment
features without violating the overlap assumption. In addition, the GPI focuses on estimating causal effects
rather than discovering of causal structure, which is another important goal of causal represetation learning
(Scholkopf et al., 2021). ¨
Finally, the GPI differs from that of Wang and Blei (2019) though both use the estimated “deconfounder” for confounding adjustment. Wang and Blei adjust the unobserved confounding by estimating the
deconfounder as a function of treatments (Imai and Jiang, 2019). In contrast, the GPI learns a representation of observed confounding by estimating the deconfounder as a function of generative model’s internal
representation of treatment objects. In this setting, we formally establish the nonparametric identification
of the average treatment effect.
2 The Experimental Design for Texts as Treatments
While the GPI is a general methodological approach, it is helpful to consider a concrete application. We use
the candidate profile experiment of Fong and Grimmer (2016) which investigates how various features of
a political candidate affect voter evaluation. In the context of this experiment, we describe our alternative
approach that uses LLMs to generate treatment texts. In Sections 4 and 5, we return to this application to
empirically evaluate the performance of the GPI.
2.1 Candidate profile experiment
Fong and Grimmer (2016) collected 1,246 candidate biographies (written in texts) from Wikipedia, and
then asked a total of 1,886 voters to answer an online survey evaluating up to four randomly assigned
candidate profiles. Specifically, the survey asked these voters to rate each candidate biography using a
feeling thermometer that ranges from 0 (cold) to 100 (warm). The authors first used a supervised Bayesian
model based on the Indian buffet process to discover a total of 10 treatment features and then estimated the
marginal association between each treatment feature and the observed feeling thermometer value.
Unlike the original analysis, we consider a setting in which researchers have a specific treatment feature
of interest. Suppose that we are interested in estimating the causal effect of having a military background
on voter evaluation. The relevant political science literature suggests that the experience and occupation of
candidates play an important role (e.g., Kirkland and Coppock, 2018; Campbell and Cowley, 2014; Pedersen
et al., 2019). Indeed, the original analysis shows that candidate biographies with military background tend
to receive a high feeling thermometer score.
The challenge, however, is that military background may be correlated with other features present in
candidate biographies. Table S1 of Appendix S1 displays two example biographies used in the original
experiment. The first describes a candidate with military background, whereas the second shows another
without military background. Yet, these two biographies also differ in terms of other features, including
educational background, marital status, and family structure. The length of each biography and their levels
of detail are also different. If these differences are correlated with military background and influence voter
evaluation, a simple comparison between biographies with military background and those without it would
lead to biased causal estimates.
2.2 Using large language models to (re)generate treatment texts
We use an LLM to generate treatment texts. In the current context, we can achieve this in two ways. First,
we can provide a prompt to an LLM, asking it to generate a candidate biography from scratch. Alternatively,
we can use existing biographies (e.g., those collected by Fong and Grimmer (2016)) and then ask an LLM
to reproduce the same biographies without any modification.
Both approaches require (1) the coding of the treatment variable (e.g., the existence of military back4
ground) and (2) the extraction of the internal representation of LLM used to generate treatment texts. The
first requirement may mean that human coders have to read treatment texts unless one is willing to assume
that LLM has a good compliance with the instruction in the prompts. The second requirement implies
that we should use open-source LLMs including GPT (Generative Pre-trained Transformer), Llama (Large
Language Model Meta AI), and OPT (Open Pre-trained Transformer).
Table S2 of Appendix S1 shows an example from each approach. Here, we use Meta’s Llama 3
instruction-tuned model with eight billion parameters. This model takes two types of inputs: system-level
inputs (System), which define the type of task to be performed, and user-level inputs (User), which define a
specific task to be performed. The first example in the table shows how the model generates a new candidate
biography with military background from scratch, whereas the second shows how the model reproduces a
given biography. The former suggests that an LLM can create realistic treatments, while the latter indicates
that it can follow the instruction accurately.
We emphasize that the use of LLM in itself does not automatically solve the confounding bias. This
is because the LLM learns the associations of words in real-world texts, and even if one manipulates the
concepts with instructions, other correlated concepts might also be influenced, causing the confounding bias
(Hu and Li, 2021).
3 The Proposed Methodology
We turn to the proposed GPI methodology that adjusts for confounding features in unstructured treatment
objects such as texts to estimate the causal effects of the specific treatment feature. We begin by defining
the causal quantity of interest, establish its nonparametric identification, and then develop an estimation
strategy.
3.1 Assumptions and causal quantity of interest
Consider a simple random sample of N respondents drawn from a population of interest. For each respondent i = 1, 2, . . . , N, we assign a prompt Pi
that is randomly and independently sampled from a set of
potential prompts P. In our application, the prompts are based on natural language (e.g., “Create a biography of an American politician who has some military experience”). Given each prompt, we use a deep
generative model to generate a treatment object such as text, denoted by Xi ∈ X where X is the support of
Xi
.
We use a broad definition of a deep generative model to encompass LLMs and other foundation models.
Indeed, our definition includes many models for texts (e.g., Touvron et al., 2023; Zhang et al., 2022; Jiang
et al., 2023a) and images (e.g., Ramesh et al., 2021; Rombach et al., 2022).
DEFINITION 1 (DEEP GENERATIVE MODEL) A deep generative model is the following probabilistic model
that takes prompt Pi as an input and generates the treatment object Xi as an output:
P(Xi
| hγ(Ri))
P(Ri
| Pi)
where Ri ∈ R ⊂ R
dR denotes an observable internal representation of Xi contained in the model and
hγ(Ri) is a deterministic function parameterized by γ that completely characterizes the conditional distribution of Xi given Ri
.
Under this definition, R represents a lower-dimensional representation of the treatment object X and is a
hidden representation of neural networks. In addition, hγ(R) is the propensity function (Imai and van Dyk,
2004) and is both known and observable in an open-source deep generative model. Thus, the treatment
object X depends on P only through hγ(R). Note that any given text Xi can have multiple internal
representations. For example, one can first instruct an LLM to generate a new text and then ask it to
5
repeat the generated text exactly. These two prompts will produce the same text but yield different internal
representations. In Section 4.3, our simulation study shows that the internal representation of regenerated
text leads to more efficient causal estimates.
In the proposed experiment, each respondent i is exposed to the generated treatment object Xi
, and
subsequently generates the outcome variable Yi ∈ Y ⊂ R where Y is its support. In our application, the
treatment object is a candidate biography and the outcome is a respondent’s evaluation of the biography.
Let Yi(x) denote the potential outcome of respondent i when exposed to a treatment object x ∈ X . Then,
the observed outcome is solely determined by the assigned treatment object, i.e., Yi = Yi(Xi). This
experimental design implies the following two assumptions.
ASSUMPTION 1 (CONSISTENCY) The potential outcome under the treatment object x ∈ X , denoted by
Yi(x), equals the observed outcome Yi under the realized treatment object Xi:
Yi = Yi(Xi).
ASSUMPTION 2 (RANDOM ASSIGNMENT OF PROMPT) Prompt is randomly assigned such that the following independence holds for all i and x ∈ X :
Yi(x) ⊥⊥ Pi
.
We estimate the causal effect of a particular feature that can be part of a treatment object. For simplicity,
we consider a binary treatment feature denoted by Ti for each i. In our application, Ti = 1 if candidate
biography i contains military background and Ti = 0 otherwise. We assume that the treatment feature is
determined solely by the treatment object (Egami et al., 2022).
ASSUMPTION 3 (TREATMENT FEATURE) There exists a deterministic function gT : X → {0, 1} that
maps a treatment object Xi
to a binary treatment feature of interest Ti
, i.e.,
Ti = gT (Xi).
This assumption is violated, for example, if respondents infer different values of the treatment feature from
the same treatment object. We address this issue in Appendix S3 by considering perceived treatment, which
reflects heterogeneity between respondents.
Next, we define confounding features, which represent all features of X other than the treatment feature T that influence the outcome Y . These confounding features, denoted by U ∈ U, are based on a
vector-valued deterministic function of X where U denotes their support. The confounding features may
be multidimensional, though we assume that its dimensionality is much smaller than that of the treatment
object. In our application, confounding features may include other candidate characteristics and textual
features of biographies, such as their length. These confounding features are possibly correlated with the
treatment feature. Unlike the treatment feature, however, we do not directly observe the confounding features. Formally, the confounding features are defined as follows (Fong and Grimmer, 2023; Pryzant et al.,
2021).
ASSUMPTION 4 (CONFOUNDING FEATURES) There exists an unknown vector-valued deterministic function gU : X → U that maps an unstructured object Xi ∈ X to the confounding features Ui ∈ U, i.e.,
Ui = gU (Xi),
where dim(Ui) ≪ dim(Xi).
6
Finally, we introduce our key assumption that the potential outcome is a function of treatment and
confounding features and that we can intervene the treatment feature without changing the confounding
features. In other words, the treatment feature cannot be represented as a deterministic function of the confounding features. In addition, confounding features should not vary as a deterministic function of treatment
feature in order to avoid “posttreatment” bias (Daoud et al., 2022). In the candidate biography application,
the assumption essentially implies that researchers need to be able to imagine hypothetical candidate biographies with and without military background while keeping the confounding features constant. We formalize
this assumption as follows.
ASSUMPTION 5 (SEPARABILITY OF TREATMENT AND CONFOUNDING FEATURES) The potential outcome is a function of the treatment feature of interest t and another separate function of the confounding
features u. That is, for any given x ∈ X and all i, we have:
Yi(x) = Yi(t,u) = Yi(gT (x), gU (x)),
where t = gT (x) ∈ {0, 1} and u = gU (x) ∈ U. In addition, gT and gU are separable. That is, there
exists no deterministic function g˜T : U → {0, 1}, which satisfies gT (x) = ˜gT (gU (x)) for some x ∈ X .
Similarly, there exist no deterministic functions g
′
: X → X ′ and g˜U : {0, 1} × X ′ → U, which satisfy
gU (x) = g˜U (gT (x), g
′
(x)) for all x ∈ X and g˜U (1, g
′
(x
′
)) ̸= g˜U (0, g
′
(x
′
)) for some x
′ ∈ X .
The first requirement of separability (i.e., no existence of g˜T ) implies that the treatment should not be
a deterministic function of confounding features, whereas the second requirement (i.e., no existence of g
′
and g˜U ) means that the confounding features cannot vary as a deterministic function of treatment. Thus,
the separability assumption holds when the treatment feature does not completely overlap with the other
features that influence the outcome (i.e., confounding features). In Appendix S2, we provides two simple
examples: one, in which the separability assumption holds, and the other one, where it is violated.
As shown in Section 3.2, Assumption 5 plays an essential role in the identification of causal effects.
Importantly, Assumptions 3–5 imply the standard overlap condition in causal inference, which enables to
identify causal effects without extrapolation. In practice, as demonstrated in Section 4.3, the violation of
Assumption 5 can be diagnosed by examining if the estimated propensity scores take extreme values. The
following lemma formally establishes that the separability assumption implies the overlap condition.
LEMMA 1 (OVERLAP) Under Assumptions 3–5, for any t ∈ {0, 1} and u ∈ U,
P(Ti = t | Ui = u) > 0.
The proof is given in Appendix S4.1.
Under this setup, we estimate the average causal effect of the treatment feature while controlling for the
confounding features. This average treatment effect (ATE) is defined as follows:
τ := E[Yi(1, Ui) − Yi(0, Ui)]. (1)
3.2 Nonparametric identification
Figure 1 presents a directed acyclic graph (DAG) that summarizes the data generating process described
above. In the DAG, an arrow with double lines represents a deterministic causal relationship, while an
arrow with a single line indicates a possibly stochastic causal relationship. We consider a deep generative
model whose decoding is deterministic, meaning that the output object is a deterministic function of the
input prompt. Formally, we make the following assumption.
ASSUMPTION 6 (DETERMINISTIC DECODING) The output layer of a deep generative model is deterministic. That is, P(Xi
| hγ(Ri)) in Definition 1 is a degenerate distribution.
7
P R hγ(R) X
U = gU (X)
T = gT (X)
Y
Deep generative model
Figure 1: Directed Acyclic Graph of the Assumed Data Generating Process. A treatment object X is
generated using a deep generative model (rectangle), in which a prompt P produces an internal representation R that generates X through a propensity function hγ(R). The treatment object affects the outcome Y
through its treatment feature of interest T and other confounding features U. An arrow with red double lines
represents a deterministic causal relation while an arrow with a single line indicates a possibly stochastic
relationship.
If P(Xi
| hγ(Ri)) is stochastic, the noise introduced by the deep generative model can confound the
treatment in an unknown way. Fortunately, almost all LLMs have the option of deterministic decoding
(e.g., greedy, beam, and contrastive searches), thereby easily satisfying the assumption (e.g., Su et al.,
2022). For example, for greedy decoding, we typically only need to set the temperature parameter to zero,
instructing a model to always produce the same texts. Indeed, many LLMs also have deterministic encoding
architectures, making the entire text generation process deterministic. Similarly, for images, we can make
the final decoding step deterministic for stochastic diffusion models, including Stable Diffusion (Rombach
et al., 2022).
Given this setup, we establish the nonparametric identification of the ATE defined in Equation (1). We
prove the existence of a deconfounder function f(Ri) that satisfies the conditional independence relation
Yi⊥⊥Ri
| Ti
, f(Ri). One trivial example of the deconfounder is the confounding features Ui
, which are a
deterministic function of Ri under Assumption 6. But, the deconfounder need not be unique. In fact, we
show that it is possible to identify the ATE by adjusting for any deconfounder.
THEOREM 1 (NONPARAMETRIC IDENTIFICATION OF THE MARGINAL DISTRIBUTION OF POTENTIAL
OUTCOME) Under Assumptions 1–6, there exists a deconfounder function f : R → Q ⊂ R
dQ with
dQ = dim(Q) ≤ dR = dim(R) that satisfies the following conditional independence relation:
Yi⊥⊥Ri
| Ti = t, f(Ri) = q, (2)
where 0 < P(Ti = t | f(Ri) = q) < 1 for all t = 0, 1 and q ∈ Q. In addition, the treatment
feature and a deconfounder are separable. By adjusting for such a deconfounder, we can uniquely and
nonparametrically identify the marginal distribution of the potential outcome under the treatment condition
Ti = t for t ∈ {0, 1} as:
P(Yi(t, Ui) = y) = Z
R
P(Yi = y | Ti = t, f(Ri))dF(Ri),
for all t ∈ {0, 1} and y ∈ Y.
The proof is given in Appendix S4.2. The definition of separability is given in Assumption 5 for the treatment and confounding features given the treatment object. In Theorem 1, we apply the same definition to
the treatment feature and a deconfounder given the internal representation. Specifically, let fT : R → {0, 1}
be the function that maps the internal representation to the treatment feature. Such a function exists because
8
Ri f(Ri
;λ)
µ1(f(Ri
;λ); θ1)
µ0(f(Ri
;λ); θ0)
Yi
| Ti = 1: Treated observations
Yi
| Ti = 0: Control observations
Figure 2: Diagram Illustrating the Proposed Model Architecture. The proposed model takes an internal
representation of a treatment object Ri as an input, and finds a deconfounder f(Ri), which is a lowerdimensional representation of Ri
, and then use it to predict the conditional expectation of the outcome
µt(f(Ri)) := E[Yi
| Ti = t, f(Ri)] under each treatment arm t = 0, 1.
the treatment feature is a deterministic function of treatment object, which is in turn a deterministic function
of the internal representation by Assumption 6. Then, we assume that fT and f are separable. That is,
there exists no deterministic function ˜fT : Q → {0, 1}, which satisfies fT (r) = ˜fT (f(r)) for all r ∈ R.
Similarly, there exist no deterministic functions f
′
: Q → Q′
and f˜ : {0, 1} × Q′ → Q, which satisfy
f(r) = f˜(fT (r), f
′
(r)) for all r ∈ R and f˜(1, f
′
(r
′
)) ̸= f˜(0, f
′
(r
′
)) for some r
′ ∈ R.
We emphasize that one cannot directly adjust for the internal representation of the treatment object.
Such direct adjustment leads to the lack of overlap because, under Assumptions 3 and 6, the treatment
feature Ti
is a deterministic function of Ri
. In addition, since the deconfounder f(Ri) is typically of much
lower dimension than the internal representation of the treatment object Ri
, making adjustments for the
former leads to a more effective estimation strategy.
3.3 Estimation and inference
Given the identification result, we next consider estimation and inference. Our estimation strategy is based
on the following two observations. First, Assumption 5 implies that the deconfounder f(Ri) should not be a
function of the treatment feature Ti
. Second, the deconfounder should satisfy the conditional independence
relation given in Equation (2). For simplicity, we assume independence across observations. Technically,
if a deep generative model has a stochastic component, we can only assume the conditional independence
of observations given the internal representation. However, as discussed earlier, many language models
have the option of making the whole text generation process deterministic, guaranteeing this conditional
independence.
We use a neural network architecture based on TarNet (Shalit et al., 2017) to estimate the conditional
potential outcome function given the deconfounder, i.e.,
µt(f(Ri)) := E[Yi(t, Ui) | f(Ri)], for t = 0, 1.
Our architecture, which is summarized in Figure 2, simultaneously estimates the deconfounder and the
outcome model. Specifically, we minimize the following loss function:
{λˆ, θˆ
0, θˆ
1} = argmin
λ,θ0,θ1
1
n
Xn
i=1
{Yi − µTi
(f(Ri
;λ); θTi
)}
2
, (3)
where n is the sample size. We make the parameters of neural network explicit by letting λ represent
the parameters of deconfounder f to be estimated, and using θt
to denote the parameters of the nuisance
function µt
.
Given the above architecture, we estimate the ATE using the double machine learning (DML) framework of Chernozhukov et al. (2018), in which both the outcome and the propensity score models are estimated. Here, we estimate the propensity score model as a function of the estimated deconfounder, i.e.,
9
π(f(Ri
;λˆ)) = Pr(Ti = 1 | f(Ri
;λˆ)) after solving the minimization problem in Equation (3). Crutially, we do not model the propensity score as a function of internal representation Ri
to avoid violating
the assumption of overlap. Thus, the deconfounder only captures the features of treatment object that are
predictive of the outcome beyond the treatment, including the features that are completely unrelated to
the treatment. The deconfounder, however, will not capture the features of treatment object that affect the
outcome only through the treatment feature. So long as such features exist (Assumption 5), the overlap
assumption will hold (Lemma 1).
In the causal representation learning literature, DragonNet (Shi et al., 2019) is a popular estimation
method used by many researchers (see e.g., Veitch et al., 2020; Gui and Veitch, 2023, as well as Pryzant
et al. 2021 who also use it in their implementation code). Unlike our approach, DragonNet includes the
cross-entropy loss between the propensity score model and the treatment variable when estimating the deconfounder f(Ri). However, this joint estimation leads to P(Ti = 1 | f(Ri)) = P(Ti = 1 | Ri) due to the
fact that f(Ri) is a balancing score satisfying Ti⊥⊥Ri
| f(Ri). This is problematic because P(Ti = 1 | Ri)
is degenerate under Assumptions 3 and 6. Thus, we first estimate the deconfounder using Equation (3) and
then model the propensity score given the estimated deconfounder.
In sum, the entire estimation procedure can be described as follows. Denote the observed data by
D := {Di}
N
i=1 where Di
:= {Yi
, Ti
, Ri}. We use the following K-fold cross-fitting procedure, assuming
that N is divisible by K.
1. Randomly partition the data into K folds of equal size where the size of each fold is n = N/K. The
observation index is denoted by I(i) ∈ {1, . . . , K} where I(i) = k implies that the ith observation
belongs to the kth fold.
2. For each fold k ∈ {1, · · · , K}, use observations with I(i) ̸= k as training data:
(a) split the training data into two folds, I
(−k)
1
and I
(−k)
2
(b) simultaneously obtain an estimated deconfounder and an estimated conditional outcome function on the first fold, which are denoted by fˆ(−k)
({Ri}
i∈I
(−k)
1
) := f({Ri}
i∈I
(−k)
1
;λˆ(−k)
) and
µˆ
(−k)
t
({Ri}
i∈I
(−k)
1
) := µt(f({Ri}
i∈I
(−k)
1
;λˆ(−k)
); θˆ(−k)
), respectively, by solving the optimization problem given in Equation (3), and
(c) obtain an estimated propensity score given the estimated deconfounder on the second fold,
which is denoted by πˆ
(−k)
(fˆ(−k)
({Ri}
i∈I
(−k)
2
)) := ˆπ
(−k)
(f({Ri}
i∈I
(−k)
2
;λˆ(−k)
)).
3. Compute the GPI estimator τˆ as a solution to:
1
nK
X
K
k=1
X
i:I(i)=k
ψ(Di
; ˆτ, fˆ(−k)
, µ
(−k)
1
, µ
(−k)
0
, πˆ
(−k)
) = 0, (4)
where
ψ(Di
; τ, f, µ1, µ0, π)
=
Ti{Yi − µ1(f(Ri))}
π(f(Ri)) −
(1 − Ti){Yi − µ0(f(Ri))}
1 − π(f(Ri)) + µ1(f(Ri)) − µ0(f(Ri)) − τ.
(5)
To derive the asymptotic properties of the proposed GPI estimator, we assume the following regularity
conditions.
10
ASSUMPTION 7 (REGULARITY CONDITIONS) Let c1, c2, and q > 2 be positive constants and δn be a sequence of positive constants approaching zero as the sample size n increases. Then, the following conditions
hold.
(a) (Primitive conditions)
E[|Yi
|
q
]
1/q ≤ c1, sup
r∈R
E[|Yi − µTi
(f(r))|
2
| Ri = r] ≤ c1, E[|Yi − µTi
(f(Ri))|
2
]
1/2 ≥ c2.
(b) (Outcome model estimation)
E[|µˆTi
(fˆ(Ri)) − µTi
(f(Ri))|
q
]
1/q ≤ c1, E[|µˆTi
(fˆ(Ri)) − µTi
(f(Ri))|
2
]
1/2 ≤ δnn
−1/4
.
(c) (Deconfounder estimation)
E
h

fˆ(Ri) − f(Ri)



q
i1/q
≤ c1, E


fˆ(Ri) − f(Ri)



2
1/2
≤ δnn
−1/4
(d) (Propensity score estimation) π(·) is Lipschitz continuous at the every point of its support, and satisfies:
E[|πˆ(f(Ri)) − π(f(Ri))|
q
]
1/q ≤ c1, E[|πˆ(f(Ri)) − π(f(Ri))|
2
]
1/2 ≤ δnn
−1/4
.
Like the standard application of DML, the required rate for nonparametric estimation of nuisance models is
slower than the usual parametric estimation rate of n
−1/2
. Recall that we use neural networks for the joint
estimation of outcome model and deconfounder. The required convergence rate of n
−1/4
is achievable with
the standard neural network architecture (Farrell et al., 2021). The propensity score function can be estimated using various nonparametric methods, including the feedforward neural networks with regularization
to ensure Lipschitz continuity (Gouk et al., 2021) and the kernel-based methods with nonexpansive kernels
(van Waarde and Sepulchre, 2022).
Given the above assumptions, the asymptotic normality of the proposed GPI estimator follows immediately from the DML theory.
THEOREM 2 (ASYMPTOTIC NORMALITY OF THE GPI ESTIMATOR) Under Assumptions 1–7, the estimator τˆ obtained from the influence function ψ satisfies asymptotic normality:
√
n(ˆτ − τ )
σ
d−→ N (0, 1)
where σ
2 = E[ψ(Di
; τ, f, µ1, µ0, π)
2
].
The proof is given in Appendix S4.3. In addition, we can consistently estimate the asymptotic variance
using the plugin estimator based on Equation (5).
3.4 Practical implementation details
We discuss some important practical implementation details. First, to satisfy Assumption 6, researchers
must choose a deep generative model that has the option of deterministic decoding. Aside from appropriately setting a hyper-parameter, the assumption also implies that we should not use batches with LLMs,
which may induce unknown correlations across observations. The use of LLMs that have memory should
also be avoided.
11
In addition, the effective implementation of the proposed estimation method requires a careful choice of
dimension reduction strategy for the internal representation, as well as hyperparameter tuning for TarNet.
First, the internal representation Ri
, which typically corresponds to the last hidden states of a deep generative model, is of high dimension. Specifically, it is a matrix of size equal to the length of texts × the size
of representation for each token, which is equal to 768 for BERT-base, 1024 for BERT-large and T5-3B,
and 4096 for Llama3-8B. In theory, we can directly incorporate this matrix in TarNet. In practice, however, given the limited computational resources available to researchers, it is advisable to apply a pooling
operation to reduce the dimensionality.
The choice of pooling strategy depends on the architecture of a deep generative model. For example,
in BERT, the first special classification token [CLS] contains all semantic information (Devlin et al., 2019).
Thus, we could use the hidden states that correspond to this [CLS] token alone. In BART (Bidirectional
and Auto-Regressive Transformers), the special token is added at the end, so researchers can extract the
hidden states of the last token (Lewis et al., 2020). In contrast, encoder-decoder models like T5 (Text-toText Transfer Transformer, Raffel et al. 2023) do not have such special tokens, and mean pooling is often
applied (e.g., Ni et al. 2021).
For decoder-only models, such as Llama, the autoregressive structure forces all tokens to pay attention
only to the past tokens. Hence, we can use the hidden states of the last token. This pooling strategy is
frequently used as an approximation of the input text representation in the literature (e.g.,Neelakantan et al.
2022; Ma et al. 2024; Jiang et al. 2023b). We show the validity of this approximation in a simulation
study (Section 4). Our experience shows that this approximation generally works well. If the confounding
features are deemed too complex to be adequately captured by the last token alone, researchers may consider
a sensitivity analysis (Lin et al., 2024).
Second, for TarNet, we must carefully choose hyperparameters such as the size and depth of layers,
learning rate, and maximum epoch size. Together, they determine the success of optimization and the
quality of the deconfounder estimate. The dimension of the deconfounder should be sufficiently large to
capture the confounding information, but not too large to violate the overlap assumption. The learning rate
and the epoch size are also crucial, as the performance is highly dependent on the success of the optimization
process.
A practical strategy is to try different hyperparameter values and select the one that minimizes the loss.
If the loss does not decrease within the first few epochs, the optimization has likely failed, and researchers
should try different hyperparameter values. The process can be automated with advanced hyperparameter optimization methods, such as Optuna (Akiba et al., 2019), that search the optimal hyperparameters
efficiently by dynamically constructing the search space.
3.5 Diagnostic tools
The key assumption of the GPI methodology is the separability between the treatment and confounding
features (Assumption 5). This assumption concerns the functional relationship between the treatment and
confounding features: (i) the treatment feature Ti
is not a deterministic function of Ui
, and (ii) the confounding feature Ui
is not a function of Ti
. As we show in Lemma 1, condition (i) implies the overlap assumption.
Condition (ii) implies that the confounding feature Ui
is disentangled from the treatment feature Ti
, so that
P

Ui
| do(Ti = t)

= P

Ui

for all t ∈ T . Wang and Jordan (2024) show that disentanglement implies
the independence of support, i.e., supp(Ti) × supp(Ui) = supp(Ti
, Ui), which is a necessary condition
for positivity. Therefore, checking positivity is crucial for diagnosing the potential violation of separability
assumption.
We propose two ways to diagnose the positivity assumption. The first way is to plot the distribution of
the estimated propensity scores πˆ(fˆ(Ri)) = P(Ti = 1\| fˆ(Ri)) and assess whether they are bounded away
from 0 and 1. If some estimated scores are too close to 0 or 1, one may trim them (Crump et al., 2009), clip
12
them (Dorn, 2025), or use overlap weights (Li et al., 2019).
Another way to diagnose the potential violation of positivity is to compute the independence-of-support
score (IOSS) proposed by Wang and Jordan (2024). We use IOSS to measure the dependence of support
between the deconfounder and the treatment variable. After standardization, IOSS lies in [0, 1] and can be
interpreted as the fraction of the standardized range by which the support of the two variables would need
to be shifted in order to achieve perfect overlap.
The separability assumption also requires that the treatment feature can be manipulated independently
of the confounding features. This implication is challenging to verify statistically. One practical approach is
to instruct either an LLM or human to alter only the treatment feature while keeping the remaining aspects
of the original text unchanged. The GPI methodology can then be applied to estimate treatment effects. If
the manipulation is successful, the resulting treatment effect estimates should closely match those based on
the original data. A limitation of this approach is that one needs to collect outcome data for the altered texts.
Nevertheless, this provides a direct test of a core component of the separability assumption.
4 Simulation Studies
We conduct simulation studies to evaluate the empirical performance of the GPI estimator and compare it
to existing estimators.
4.1 Simulation setup
We use the candidate profile experiment introduced in Section 2 to make the simulation setup realistic.
We first generate candidate biographies using an open source LLM, Llama3–8B, that is fine-tuned for
instruction-based prompt generations with 8 billion parameters. We ask the model to create a biography
of politicians under a hypothetical name using the system and user level prompts shown in Table S2 of
Appendix S1. We create hypothetical names by randomly drawing a surname and a first/middle name with
replacement from the original corpus of Fong and Grimmer (2016). The total number of biographies in our
sample is 4,000.
We also examine the performance of the GPI methodology with the text reuse approach. To do this, we
instruct the same Llama3 model to exactly repeat each generated biography. This allows us to compare our
two approaches using the same set of texts.
After generating candidate biographies, we label them based on treatment and confounding features of
interest. We consider two scenarios: the first is designed to adhere to the separability assumption (Assumption 5), which is our key assumption, while the second is likely to violate it. For the first scenario, we use the
candidate’s military background as the treatment variable. A biography is assigned to the treatment group
if it contains at least one of the following keywords: “military,” “veteran,” or “army.”
For confounding features, we first consider a combined topic of politics and education, denoted as
h1(Xi) where h1 is a complex function of the treatment object. We employ a widely-used embeddingbased topic model, BERTopic (Grootendorst, 2022), and then assign h1(Xi) = 1 if a generated biography
is classified to a topic whose representative words include “politics,” “student,” “college,” “elected,” “university,” “political,” “advocate,” and “education”. As the second confounding feature, denoted by h2(Xi),
we use the sentiment analysis module available in the Python TextBlob package, which yields a continuous sentiment score ranging from −1 to 1. Since the treatment feature is based on a set of specific keywords
that are quite different from the confounding features, the separability assumption is likely to be satisfied
under this scenario.
For the second scenario, we use two overlapping topics to define the treatment and confounding features
so that the separability assumption is likely to be violated. We again use topics obtained from BERTopic,
and assign Ti = 1 if a generated biography is classified to a topic whose representative words include
“college,” “political,” “elected,” “politics,” “student,” “senator,” “education,” and “legislative”. For the
confounding concept, we set h1(Xi) = 1 if a biography is assigned to a topic whose representative words
13
include “college,” “political,” “senator,” “politics,” “elected,” “student,” and “career”. Thus, although the
treatment and confounding concepts are coded based on two different topics, they share many representative
words, making it likely for the separability assumption to be violated.
Finally, we use the following linear model to generate the outcome variable,
Yi = α1Ti + α2Tih1(Xi) − α3h1(Xi) − α4h2(Xi) + ϵi
,
where ϵi
is the standard normal random variable. Although the model may appear to be a relatively simple
function of the treatment and confounding features, these variables themselves are complex functions of
text. Thus, in this simulation setting, inferring the ATE is not straightforward because it requires learning
an accurate representation of confounding features.
To evaluate the performance of each estimator, we assume that researchers do not have access to the confounding features, h1(Xi) and h2(Xi). We wish to infer the ATE, which is given by τ = α1+α2E[h1(Xi)]
where we set α1 = α2 = 10 throughout the simulations. We consider the three scenarios: (1) weak confounding α3 = α4 = 50, (2) moderate confounding α3 = α4 = 100, (3) strong confounding α3 = α4 =
1000. Given the computational cost, our evaluation is conditional on a single set of generated biographies
and its associated treatment and confounding variables. Therefore, E[h1(Xi)] is set to its sample mean, and
the randomness comes only from the error term of the outcome model ϵi
.
4.2 Estimators to be compared
Once Llama3 generates all biographies, we extract an internal representation of each biography from the last
hidden layer whose dimension is 4096 × the number of tokens contained in the biography. For text reuse,
we ask the LLM to repeat each generated text. To compute the GPI estimator, we follow the discussion
presented in Section 3.4 and use the representation of the last token, yielding a 4096 dimensional vector of
internal representation for each candidate biography.
Our neural network architecture uses one linear layer for the deconfounder f(Ri) whose output dimension is 2048. Similarly, we utilize two consecutive linear layers for the potential outcome models whose
output dimensions are 500 and 1. We apply ReLU as an activation function between each layer, and also use
a dropout rate of 0.15 to prevent overfitting. We select the neural network architecture, including dropout
rates, layer depth, and dimension of each layer, based on additional hyperparameter tuning under the weak
confounding setting. While we do not conduct hyperparameter tuning for each setting separately, we find
that minor changes in these hyperparameters do not significantly affect the value of the loss function.
We use 40% of our data as a training set, 10% as a validation set, and the remaining 50% is used to
estimate downstream causal effects. For optimization, we set the batch size to 32 and train the model for 500
epochs, and use early stopping to prevent overfitting. Specifically, we stop training if the estimated loss does
not improve for more than 15 epochs. Since the performance of the methodology can depend on the choice
of hyperparameters, especially learning rates, we select learning rates using an automated hyperparameter
tuning package Optuna. We do not include the size of the deconfounder as a hyperparameter to be tuned
because tuning it for the BERT-based methods is computationally too expensive. We also do not observe
any substantial difference in performance when varying the dimensions of the deconfounder for the GPI
methodology. Once the outcome model is fitted, we estimate the propensity score using a random forest
classifier with the estimated deconfounder, using the scikit-learn library.
We evaluate the performance of the GPI estimator in comparison to the following three estimators.
First, as a baseline, we use the difference-in-means estimator, which makes no adjustment for confounding.
Second, we implement the two existing approaches that estimate the vectorized representation of texts using
the BERT embedding b(·); Pryzant et al. (2021) estimates nuisance functions with TarNet and calculates the
causal effect using outcome models, while Gui and Veitch (2023) uses the same outcome models as Pryzant
et al. (2021) but applies DML with the estimated propensity score. Importantly, both of these approaches
14
Absolute Bias
weak moderate strong
0
10
100
0
10
100
RMSE
weak moderate strong
0
10
100
1000
0
10
100
1000
95% CI Coverage
weak moderate strong
0.00
0.25
0.50
0.75
1.00
0.00
0.25
0.50
0.75
1.00
Avg. Runtime (sec.)
Under separability No separability
weak moderate strong
30
100
300
1000
3000
30
100
300
1000
3000
GPI (new texts) GPI (text reuse) Outcome Model with BERT DML with BERT
Figure 3: Performance of Five Estimators under Different Confounding Scenarios (Weak, Moderate, and
Strong) under Separability (top row) and No Separability (bottom row). A red solid line represents the proposed GPI methodology for the new texts, while a dark yellow solid line represents that for the regenerated
texts (text reuse). For comparison, we also include outcome model with BERT (blue) and DML with BERT
(purple). The black horizontal dotted line in the 95% Confidence Interval (CI) Coverage panel represents
the nominal coverage of 95%.
are based on the following loss function,
λ
n
Xn
i=1
{Yi − QTi
(b(Xi))}
2−
α
n
Xn
i=1

Ti
log g(b(Xi))+ (1−Ti) log[1−g(b(Xi))]
+
1
n
Xn
i=1
B(bfull(Xi))
(6)
where Qt(·) is the outcome model under Ti = t, g(·) is the treatment prediction, B(·) is the original BERT
masked language loss for estimating vector representations of texts from the embedding b(·), and α, λ ∈ R
are the hyperparameters (Veitch et al., 2020). Only the vector representation of the first token b(·) is used
for prediction of outcome and treatment because it is the special token called the [CLS] token that contains
the semantic information. On the other hand, for the masked language loss, the entire embedding bfull(·) is
used. The loss function given in Equation (6) differs from our loss function (Equation (3)) in that in addition
to the outcome model, it optimizes the representation learning from texts and the prediction of treatment.
After estimating nuisance functions, Gui and Veitch (2023) proposes to estimate the propensity score
model by treating Q1(b(Xi)) and Q0(b(Xi)) as covariates, i.e., Pr(Ti = 1 | Xi) = g(Q1(b(Xi)), Q0(b(Xi))).
For propensity score estimation, we use a Gaussian Process, as recommended by Gui and Veitch (2023).
We truncate the extreme values of the estimated propensity scores at 0.01 and 0.99 for DML with BERT,
although such a truncation is not necessary for the GPI methodology. For DML with BERT, this truncation
occurs even when the separability assumption is satisfied (5% of time for weak and moderate confounding, and 45% for strong confounding). Without truncation, the bias and RMSE are not computable for
these methods. Finally, we follow the default hyperparameter used in the authors’ original code and set
α = λ = 1 while tuning the other hyperparameters regarding the learning rate in the same way as done for
the GPI estimator.
4.3 Simulation results
Figure 3 graphically displays the results of our simulation studies while Appendix S5 reports the corresponding numerical results. The results are based on 200 Monte Carlo trials. We choose this relatively
15
Figure 4: Distribution of the Estimated Propensity Scores for the Treatment (red) and Control (blue) Groups.
We present the results for the proposed GPI estimator (new texts in the left panels, and text reuse in the
middle panels), and DML with BERT (right) under the separability assumption (top) and no separability
(bottom). Under each scenario, we present the results based on three different strengths of confounding;
weak, moderate, and strong. For the proposed GPI methodology, the estimated propensity scores are distributed similarly across different confounding scenarios under the separability assumption. In contrast, for
DML with BERT, the distribution is heavily skewed right under the strong confounding scenario. When the
separability assumption is violated, both methods have extremely small estimated propensity scores for the
control group.
small number of trials because, unlike the GPI estimator, the BERT-based estimators are computationally
intensive. Appendix S5 also presents the simulation results based on 1,000 Monte Carlo trials for the proposed estimator alone. As expected, the results are qualitatively similar to those presented in this section.
We find that when the separability assumption holds (top row), the GPI estimators (red line for new
texts and dark yellow for text reuse) exhibit a smaller bias and RMSE compared to all other estimators, with
the 95% confidence interval coverage closely matching the nominal rate. The performance differences are
particularly striking in the strong confounding setting, where DML with BERT (purple) performs poorly,
unlike the weak and moderate confounding scenarios. Additionally, outcome model with BERT (blue) has
severe undercoverage across all simulation scenarios, whereas the confidence interval of DML with BERT
breaks down only under the strong confounding scenario. Lastly, the GPI estimators are more than ten times
as computationally efficient as BERT-based estimators, when measured in terms of the average runtime.
In contrast, when the separability assumption is violated (bottom row), all estimators, including ours,
perform poorly. In this setting, both bias and RMSE grow as the strength of confounding increases. As a
result, the coverage of confidence intervals no longer approximates the nominal coverage rate even for the
GPI estimator.
We further examine the difference in performance between the GPI estimator and the DML with BERT.
Figure 4 shows the distribution of the estimated propensity scores without truncation (recall that truncation
is not needed for the proposed methodology). For the GPI methodology, when the separability assumption
is met (top panel), the distribution of estimated propensity scores is relatively symmetric regardless of the
confounding strength and is similar between the treatment and control groups. Indeed, most observations
have estimated propensity scores far from zero. This explains why the GPI estimator performs well in this
scenario.
16
Bias RMSE Coverage
1000 2000 3000 4000 1000 2000 3000 4000 1000 2000 3000 4000
0.00
0.25
0.50
0.75
1.00
5
10
15
20
5
10
Sample Size
GPI (new texts) GPI (text reuse)
Figure 5: Performance of the GPI Estimator on the created texts (red) and the reused texts (blue) for Different Sample Size based on 1000 Monte Carlo trials. The data generating process is no interaction setting
(α1 = 10, α2 = 0, α3 = α4 = 100). The black dotted line in the coverage panel represents the nominal
coverage of 95%.
On the other hand, when the separability assumption is violated (bottom left and middle panels), the
estimated propensity scores for the control group are heavily skewed to the right and close to zero, indicating
that the overlap assumption is violated. This implies that the estimated propensity scores can help diagnose
the potential violation of the separability assumption for our proposed method, which leads to complete
entanglement between treatment and confounding features and causes the deconfounder to perfectly predict
the treatment assignment. In contrast, DML with BERT yields a wide range of estimated propensity scores
under the strong confounding settings (top right panel), in which the estimator performs poorly. This pattern
is observed even when the separability assumption is violated (bottom right panel). The finding implies that,
unlike the proposed estimator, extreme values of estimated propensity scores may not serve as a reliable
diagnostic for DML with BERT.
Finally, we examine the performance of the GPI estimator for new texts and text reuse as we vary the
sample size from 1,000 to 4,000 under the assumption of separability. For this simulation, we use the
moderate confounding setting without the interaction term (α1 = 10, α2 = 0, α3 = α4 = 100) so that
the true ATE stays identical across sample sizes. We conduct 1,000 Monte Carlo trials as we focus only
on the GPI estimator, which is computationally efficient. Figure 5 presents bias, RMSE, and coverage for
each sample size. As expected, both bias and RMSE become smaller as the sample size increases. We also
find that the empirical coverage of the 95% confidence intervals remains close to the nominal coverage even
when the sample size is as small as 1000. Interestingly, while bias is similar between new texts and text
reuse, RMSE (hence variance) is substantially smaller for text reuse. In sum, the proposed GPI methodology
performs well in different sample sizes, provided that the separability assumption is satisfied.
5 Empirical Analysis
Finally, we apply the proposed GPI methodology to human responses (rather than simulated data) from
the candidate profile experiment of Fong and Grimmer (2016) using pre-defined treatment coding. In the
original experiment, the authors scraped 1,246 biographies of congressional candidates from Wikipedia,
randomly assigned up to four biographies to 1,886 survey participants, and asked respondents how they felt
about each candidate using the standard feeling thermometer ranging from 0 to 100, where a higher value
indicates a more favorable evaluation. The total number of observations we analyze is 5,291 after dropping
17
Methods ATE Estimates 95% Confidence Interval IOSS Runtime (sec.)
GPI (reuse) 4.852 [1.902, 8.580] 0.10 62.3
Outcome model with BERT −4.277 [−4.312, −4.241] 0.41 5914.0
DML with BERT 45.708 [33.730, 57.686] 5986.2
Table 1: The Estimated Average Treatment Effect (ATE) for the Candidate Profile Experiment.
some observations with empty texts.
While Fong and Grimmer (2016) use a topic model to discover treatments from the data, we use the
pre-defined treatment coding. As in simulation studies, we use a candidate’s military background as the
treatment variable by assigning a biography to the treatment group if it contains at least one of the following
keywords: “military,” “veteran,” and “army.” According to this coding rule, only seven percent of the
biographies (362 out of 5,291) are in the treatment group.
For causal effect estimation, we take the text reuse approach by regenerating each biography using
Llama3-8B. We then apply the proposed GPI methodology following the procedure described in Section 3
with two-fold cross fitting. For comparison, as in our simulation studies, we also apply the two existing
BERT-based methods — Pryzant et al. (2021) (Outcome model with BERT) and Gui and Veitch (2023)
(DML with BERT).
Table 1 presents the results. The analysis based on the proposed GPI methodology implies that military experience has a positive effect and is statistically significant. This echoes with the finding of Fong
and Grimmer (2016) that the topic corresponding to military experience has a statistically significant positive association with a higher feeling thermometer score. In contrast, outcome model with BERT yields a
negative and statistically significant estimate, while DML with BERT produces a positive estimate that is
unreasonably large given the scale is between 0 and 100.
To diagnose the potential violation of positivity, we also compute IOSS for both the GPI and BERTbased methods. While GPI yields IOSS of 0.10, the BERT-based methods yield a much larger IOSS of
0.41. This suggests that the separability assumption is much more likely to be voilated for the BERT-based
methods than GPI. Indeed, for the BERT-based methods, all 5291 observations have estimated propensity
scores outside of the range of [0.01, 0.99].
Lastly, as observed in our simulation studies, the runtime for GPI is around 100 times shorter than that
of the two BERT-based estimators.
6 Concluding Remarks
In this paper, we demonstrate that the use of GenAI can significantly enhance the validity of causal inference
with unstructured treatments, such as texts and images. We leverage GenAI to both efficiently produce a
variety of treatments and precisely control confounding bias. By utilizing the true vector representation of
generated texts, we avoid estimating such representation as done in the previous methods, leading to more
efficient and robust causal effect estimation.
We formalize the conditions required for nonparametric identification, showing that the separability of
treatment and confounding features plays an essential role. We also develop an estimation method based on
a neural network architecture that mitigates the risk of positivity violation, a common problem of existing
methods. Lastly, we extend the proposed GPI methods to the settings of perceived treatments, using an
instrumental variables approach. Our simulation study shows that the GPI estimator outperforms existing
methods.
Although we have focused on texts as treatments, our GPI approach can be extended to other types of
unstructured data, such as images and videos. For images, we expect the proposed GPI methodology to
18
be directly applicable so long as the dimensionality of internal representation is relatively low. For videos,
both treatment and confounding features are likely to exhibit complex relationships due to the combination
of audio and images with the additional temporal dimension. Thus, the GPI methodology described here is
not readily applicable. Future work should consider how to leverage the internal representation of videos
obtained from GenAI.
References
Ahrens, M., Ashwin, J., Calliess, J.-P., and Nguyen, V. (2021). Bayesian Topic Regression for Causal
Inference. arXiv:2109.05317 [cs, stat].
Akiba, T., Sano, S., Yanase, T., Ohta, T., and Koyama, M. (2019). Optuna: A Next-generation Hyperparameter Optimization Framework. In Proceedings of the 25th ACM SIGKDD International Conference on
Knowledge Discovery & Data Mining, KDD ’19, pages 2623–2631, New York, NY, USA. Association
for Computing Machinery.
Aronow, P. M., Baron, J., and Pinson, L. (2019). A Note on Dropping Experimental Subjects who Fail a
Manipulation Check. Political Analysis, 27(4):572–589.
Bisbee, J., Clinton, J. D., Dorff, C., Kenkel, B., and Larson, J. M. (2024). Synthetic Replacements for
Human Survey Data? The Perils of Large Language Models. Political Analysis, pages 1–16.
Blackwell, M., Brown, J. R., Hill, S., Imai, K., and Yamamoto, T. (2025). Priming bias versus post-treatment
bias in experimental designs. Political Analysis, Forthcoming.
Campbell, R. and Cowley, P. (2014). What Voters Want: Reactions to Candidate Characteristics in a Survey
Experiment. Political Studies, 62(4):745–765.
Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., and Robins, J. (2018).
Double/debiased machine learning for treatment and structural parameters. The Econometrics Journal,
21(1):C1–C68.
Crump, R. K., Hotz, V. J., Imbens, G. W., and Mitnik, O. A. (2009). Dealing with limited overlap in
estimation of average treatment effects. Biometrika, 96(1):187–199.
Daoud, A., Jerzak, C. T., and Johansson, R. (2022). Conceptualizing Treatment Leakage in Text-based
Causal Inference. arXiv:2205.00465 [cs].
Dawid, A. P. (1979). Conditional Independence in Statistical Theory. Journal of the Royal Statistical
Society. Series B (Methodological), 41(1):1–31.
19
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional
Transformers for Language Understanding. arXiv:1810.04805 [cs].
Dorn, J. (2025). How much weak overlap can doubly robust t-statistics handle? arXiv preprint
arXiv:2504.13273.
Egami, N., Fong, C. J., Grimmer, J., Roberts, M. E., and Stewart, B. M. (2022). How to make causal
inferences using texts. Science Advances, 8(42):eabg2652.
Farrell, M. H., Liang, T., and Misra, S. (2021). Deep Neural Networks for Estimation and Inference.
Econometrica, 89(1):181–213.
Feder, A., Keith, K. A., Manzoor, E., Pryzant, R., Sridhar, D., Wood-Doughty, Z., Eisenstein, J., Grimmer,
J., Reichart, R., Roberts, M. E., Stewart, B. M., Veitch, V., and Yang, D. (2022). Causal Inference
in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond. arXiv:2109.00725
[cs].
Fong, C. and Grimmer, J. (2016). Discovery of Treatments from Text Corpora. In Proceedings of the
54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages
1600–1609.
Fong, C. and Grimmer, J. (2023). Causal Inference with Latent Treatments. American Journal of Political
Science, 67(2):374–389.
Gouk, H., Frank, E., Pfahringer, B., and Cree, M. J. (2021). Regularisation of neural networks by enforcing
lipschitz continuity. Machine Learning, 110:393–416.
Grootendorst, M. (2022). BERTopic: Neural topic modeling with a class-based TF-IDF procedure.
arXiv:2203.05794 [cs].
Gui, L. and Veitch, V. (2023). Causal Estimation for Text Data with (Apparent) Overlap Violations.
arXiv:2210.00079 [cs, stat].
Hu, Z. and Li, L. E. (2021). A Causal Lens for Controllable Text Generation. In Advances in Neural
Information Processing Systems, volume 34, pages 24941–24955.
Imai, K. and Jiang, Z. (2019). Comment: The challenges of multiple causes. Journal of the American
Statistical Association, 114(528):1605–1610.
Imai, K. and Nakamura, K. (2025). GenAI-Powered inference. arXiv preprint, 2507.03897.
20
Imai, K. and van Dyk, D. A. (2004). Causal Inference With General Treatment Regimes: Generalizing the
Propensity Score. Journal of the American Statistical Association, 99(467):854–866.
Imbens, G. W. and Angrist, J. D. (1994). Identification and Estimation of Local Average Treatment Effects.
Econometrica, 62(2):467–475.
Jerzak, C. T., Johansson, F., and Daoud, A. (2023a). Integrating Earth Observation Data into Causal Inference: Challenges and Opportunities. arXiv:2301.12985 [cs, stat].
Jerzak, C. T., Johansson, F. D., and Daoud, A. (2023b). Image-based Treatment Effect Heterogeneity.
In Proceedings of the Second Conference on Causal Learning and Reasoning, pages 531–552. PMLR.
ISSN: 2640-3498.
Jiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., Casas, D. d. l., Bressand, F.,
Lengyel, G., Lample, G., Saulnier, L., Lavaud, L. R., Lachaux, M.-A., Stock, P., Scao, T. L., Lavril, T.,
Wang, T., Lacroix, T., and Sayed, W. E. (2023a). Mistral 7B. arXiv:2310.06825.
Jiang, T., Huang, S., Luan, Z., Wang, D., and Zhuang, F. (2023b). Scaling sentence embeddings with large
language models. arXiv preprint arXiv:2307.16645.
Kasneci, E., Sessler, K., Kuchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh, G., ¨
Gunnemann, S., H ¨ ullermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel, C., Pfeffer, J., Poquet, ¨
O., Sailer, M., Schmidt, A., Seidel, T., Stadler, M., Weller, J., Kuhn, J., and Kasneci, G. (2023). Chatgpt for good? on opportunities and challenges of large language models for education. Learning and
Individual Differences, 103:102274.
Keith, K. A., Jensen, D., and O’Connor, B. (2020). Text and Causal Inference: A Review of Using Text to
Remove Confounding from Causal Estimates. arXiv:2005.00649 [cs].
Kirkland, P. A. and Coppock, A. (2018). Candidate Choice Without Party Labels:. Political Behavior,
40(3):571–591.
Klaassen, S., Teichert-Kluge, J., Bach, P., Chernozhukov, V., Spindler, M., and Vijaykumar, S. (2024).
DoubleMLDeep: Estimation of Causal Effects with Multimodal Data. arXiv:2402.01785 [cs, econ, stat].
Klar, S., Leeper, T., and Robison, J. (2020). Studying Identities with Experiments: Weighing the Risk of
Posttreatment Bias Against Priming Effects. Journal of Experimental Political Science, 7(1):56–60.
Kshetri, N., Dwivedi, Y. K., Davenport, T. H., and Panteli, N. (2024). Generative artificial intelligence
in marketing: Applications, opportunities, challenges, and research agenda. International Journal of
Information Management, 75:102716.
21
Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., and Zettlemoyer, L.
(2020). BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. In Jurafsky, D., Chai, J., Schluter, N., and Tetreault, J., editors, Proceedings
of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7871–7880.
Li, F., Thomas, L. E., and Li, F. (2019). Addressing Extreme Propensity Scores via the Overlap Weights.
American Journal of Epidemiology, 188(1):250–257.
Lin, V., Morency, L.-P., and Ben-Michael, E. (2024). Isolated causal effects of natural language.
Ma, X., Wang, L., Yang, N., Wei, F., and Lin, J. (2024). Fine-tuning llama for multi-stage text retrieval. In
Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 2421–2425.
Montgomery, J. M., Nyhan, B., and Torres, M. (2018). How Conditioning on Posttreatment Variables Can
Ruin Your Experiment and What to Do about It. American Journal of Political Science, 62(3):760–775.
Mozer, R., Kaufman, A. R., Celi, L. A., and Miratrix, L. (2024). Leveraging text data for causal inference
using electronic health records. arXiv:2307.03687 [cs, stat].
Mozer, R., Miratrix, L., Kaufman, A. R., and Anastasopoulos, L. J. (2020). Matching with Text Data: An
Experimental Evaluation of Methods for Matching Documents and of Measuring Match Quality. Political
Analysis, 28(4):445–468.
Neelakantan, A., Xu, T., Puri, R., Radford, A., Han, J. M., Tworek, J., Yuan, Q., Tezak, N., Kim, J. W.,
Hallacy, C., et al. (2022). Text and code embeddings by contrastive pre-training. arXiv preprint
arXiv:2201.10005.
Ni, J., Abrego, G. H., Constant, N., Ma, J., Hall, K. B., Cer, D., and Yang, Y. (2021). Sentence-T5: Scalable ´
Sentence Encoders from Pre-trained Text-to-Text Models. arXiv:2108.08877 [cs].
Pedersen, R. T., Dahlgaard, J. O., and Citi, M. (2019). Voter reactions to candidate background characteristics depend on candidate policy positions. Electoral Studies, 61:102066.
Pryzant, R., Card, D., Jurafsky, D., Veitch, V., and Sridhar, D. (2021). Causal Effects of Linguistic Properties. arXiv:2010.12919 [cs].
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. (2023).
Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. arXiv:1910.10683
[cs, stat].
22
Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., and Sutskever, I. (2021).
Zero-Shot Text-to-Image Generation. In Proceedings of the 38th International Conference on Machine
Learning, pages 8821–8831. PMLR. ISSN: 2640-3498.
Roberts, M. E., Stewart, B. M., and Nielsen, R. A. (2020). Adjusting for Confounding with Text Matching.
American Journal of Political Science, 64(4):887–903.
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B. (2022). High-Resolution Image Synthesis With Latent Diffusion Models. pages 10684–10695.
Scholkopf, B., Locatello, F., Bauer, S., Ke, N., Kalchbrenner, N., Goyal, A., and Bengio, Y. (2021). Toward ¨
causal representation learning. Proceedings of the IEEE, 109(5):612–634.
Shalit, U., Johansson, F. D., and Sontag, D. (2017). Estimating individual treatment effect: generalization
bounds and algorithms. arXiv:1606.03976 [cs, stat].
Shi, C., Blei, D., and Veitch, V. (2019). Adapting Neural Networks for the Estimation of Treatment Effects.
In Advances in Neural Information Processing Systems, volume 32.
Su, Y., Lan, T., Wang, Y., Yogatama, D., Kong, L., and Collier, N. (2022). A Contrastive Framework for
Neural Text Generation. arXiv:2202.06417 [cs].
Thirunavukarasu, A. J., Ting, D. S. J., Elangovan, K., Gutierrez, L., Tan, T. F., and Ting, D. S. W. (2023).
Large language models in medicine. Nature Medicine, 29(8):1930–1940.
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Roziere, B., Goyal, N., `
Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., and Lample, G. (2023). LLaMA: Open and
Efficient Foundation Language Models. arXiv:2302.13971 [cs].
van Waarde, H. and Sepulchre, R. (2022). Training lipschitz continuous operators using reproducing kernels.
In Learning for Dynamics and Control Conference, pages 221–233. PMLR.
Veitch, V., Sridhar, D., and Blei, D. M. (2020). Adapting Text Embeddings for Causal Inference.
arXiv:1905.12741 [cs, stat].
Wang, Y. and Blei, D. M. (2019). The blessings of multiple causes. Journal of the American Statistical
Association, 114(528):1574–1596.
Wang, Y. and Jordan, M. I. (2024). Desiderata for Representation Learning: A Causal Perspective. Journal
of Machine Learning Research, 25:1–65.
23
Zhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M., Chen, S., Dewan, C., Diab, M., Li, X., Lin, X. V.,
Mihaylov, T., Ott, M., Shleifer, S., Shuster, K., Simig, D., Koura, P. S., Sridhar, A., Wang, T., and
Zettlemoyer, L. (2022). OPT: Open Pre-trained Transformer Language Models. arXiv:2205.01068 [cs].
24
Supplementary Appendix
S1 Examples of Candidate Biography and Prompt
Candidate biography with military background
Anthony Higgins was born in Red Lion Hundred in New Castle County, Delaware. He attended Newark
Academy and Delaware College, and graduated from Yale College in 1861, where he was a member of
Skull and Bones. After studying law at the Harvard Law School, he was admitted to the bar in 1864 and
began practice in Wilmington, Delaware. He also served for a time in the United States Army in 1864.
Candidate biography without military background
Benjamin Tappan was born in Northampton, Massachusetts, the second child and oldest son of Benjamin
Tappan and Sarah (Homes) Tappan, who was a grandniece of Benjamin Franklin. Two of his younger brothers were abolitionists Arthur Tappan and Lewis Tappan. He attended the public schools in Northampton and
traveled to the West Indies in his youth. He apprenticed as a printer and engraver, also studying painting
with Gilbert Stuart. He read law to be admitted to the bar in Hartford, Connecticut, in 1799. Later that
year, he moved to the Connecticut Western Reserve and founded what is now Ravenna, Ohio, laying out the
original village in 1808. He married, March 20, 1801, Nancy Wright, sister of John C. Wright (congressman), afterwards a United States House of Representatives from Ohio. They had one son, Benjamin, born
in 1812.
Table S1: Two examples of candidate biographies with and without military background from the experiment conducted by Fong and Grimmer (2016)
25
Prompts Generated candidate biography
(System): You are a text generator who always
produces a biography of the instructed person.
(User): Create a biography of an American politician named Nathaniel C. Gilchrist
Nathaniel C. Gilchrist was an American politician who served as a member of the United States
House of Representatives from Maryland’s 4th
congressional district from 1895 to 1899. Born
on November 24, 1847, in Baltimore, Maryland,
Gilchrist was the son of a prominent family of merchants and shipbuilders. He was educated at the
Baltimore City College and later attended the University of Maryland, where he studied law. After
graduating, he was admitted to the bar and began
practicing law in Baltimore.
(System): You are a text generator who just repeats the input text.
(User): Higgins was born in Red Lion Hundred in New Castle County, Delaware. He attended Newark Academy and Delaware College,
and graduated from Yale College in 1861, where
he was a member of Skull and Bones. After studying law at the Harvard Law School, he was admitted to the bar in 1864 and began practice in Wilmington, Delaware. He also served for a time in the
United States Army in 1864.
Higgins was born in Red Lion Hundred in New
Castle County, Delaware. He attended Newark
Academy and Delaware College, and graduated
from Yale College in 1861, where he was a member of Skull and Bones. After studying law at the
Harvard Law School, he was admitted to the bar in
1864 and began practice in Wilmington, Delaware.
He also served for a time in the United States Army
in 1864.
Table S2: Two examples of generated candidate biographies with Llama 3. The system-level input (System)
defines the type of tasks to be performed, whereas the user-level input (User) defines a specific task to be
performed.
26
S2 Illustrative Examples of the Separability Assumption
In this Appendix section, we present illustrative example corpora of the separability assumption (Assumption 5). We present two examples, one in which the assumption is satisfied and the other where it is violated.
S2.1 Example corpus where the separability assumption is satisfied
Table S3 presents an illustrative example corpus, in which the separability assumption is satisfied. In this
toy example, the treatment feature Ti ∈ {0, 1} equals 1 if a text contains a male pronoun (i.e., “he,” “him,”
“his”) and 0 otherwise. The confounding feature Ui ∈ {0, 1} equals 1 if the sentence contains a “lawyer”
or “doctor” and 0 otherwise. In this small corpus, Ti and Ui are associated: Pr(Ti = 1 | Ui = 1) = 2
3
and
Pr(Ti = 1 | Ui = 0) = 1
3
. The separability assumption nevertheless holds: it is possible to change the
value of Ti by swapping male and female pronouns while leaving Ui unchanged.
Original Text Ti Ui Text with Ti = 1 Text with Ti = 0
He is a lawyer. 1 1 He is a lawyer. She is a lawyer.
She is a nurse. 0 0 He is a nurse. She is a nurse.
He writes a book. 1 0 He writes a book. She writes a book.
He is a doctor. 1 1 He is a doctor. She is a doctor.
She gets married. 0 0 He gets married. She gets married.
She is a doctor. 0 1 He is a doctor. She is a doctor.
Table S3: An example corpus where the separability assumption is satisfied. An underline represents a
change made to the text when the treatment feature is altered.
S2.2 Example corpus where the separability assumption is violated
Table S4 presents an illustrative corpus, in which the separability assumption is violated. Here, Ti = 1 if
the sentence contains the honorific “Mr.” and Ui = 1 if it contains a male pronoun (“he,” “him,” “his”). In
this setting, the editing operation that changes Ti from 0 to 1 (or vice versa) requires changing pronouns to
maintain grammatical coherence. Consequently, Ui can change when Ti
is altered, violating separability.
For instance, in the first row, switching Ti from 0 to 1 changes Ui from 0 to 1.
S3 Instrumental Variable Approach to the Perceived Treatment Feature
The methodology described in the previous section enables the estimation of the average causal effect of
the treatment feature, which is assumed to be a deterministic function of the treatment object. In some
cases, however, researchers may be interested in the causal effect of perceived treatment feature, which may
not necessarily coincide with the treatment feature itself. In addition, the perception of the same treatment
27
Original Text Ti Ui Text with Ti = 1 Text with Ti = 0
Mrs. Park loves her children. 0 0 Mr. Park loves his children. Mrs. Park loves her children.
Mr. Lee met with the team. 1 0 Mr. Lee met with the team. Mrs. Lee met with the team.
Mr. Zhou said he would pay. 1 1 Mr. Zhou said he would pay. Mrs. Zhou said she would pay.
Mrs. Li met him. 0 1 Mr. Li met him. Mrs. Li met him.
Table S4: A example corpus where the separability assumption is violated. An underline represents a change
made to the text when the treatment feature is altered.
feature may vary across respondents. For example, in our application, respondents may disagree as to what
constitutes a military background.
In this section, we extend the proposed methodology to the setting, in which the treatment feature is
used as an instrumental variable for the perceived treatment feature. As before, we describe the required
assumptions, establish nonparametric identification, and propose estimation and inference strategies.
S3.1 Assumptions and causal quantity of interest
We consider the same setting as in Section 3 except that we observe the perceived treatment feature Tei ∈
{0, 1}, which may not equal the treatment feature itself, i.e., Tei ̸= Ti for some i. We assume that a respondent’s perceived treatment feature is a function of the treatment and confounding features of the assigned
treatment object. We assume that both perceived treatment Tei and original treatment Ti are observed.
ASSUMPTION 8 (PERCEIVED TREATMENT FEATURE) The perceived treatment feature Tei ∈ {0, 1} is a
function of treatment and confounding features, i.e.,
Tei = Tei(Ti
, Ui),
where Tei(t,u) is the potential value of the perceived treatment feature when the treatment variable Ti
is
equal to t ∈ {0, 1} and the confounding variables Ui equal u ∈ U.
Importantly, under Assumption 8, different respondents may perceive the same treatment feature differently. In addition, it is also possible for confounding features to affect the perceived treatment feature. In
practice, researchers may measure the perceived treatment feature by asking respondents directly. However,
doing so may lead to the so-called priming bias, in which the act of asking this question itself draws a respondent’s attention to the treatment feature and confounds the causal effect of interest. To avoid this bias,
researchers may measure the perceived treatment feature after the outcome variable is realized. Addressing
this methodological issue is beyond the scope of this paper, but interested readers should consult a recent
literature on the topic (see e.g., Montgomery et al., 2018; Aronow et al., 2019; Klar et al., 2020; Blackwell
et al., 2025).
To identify the causal effect of the perceived treatment feature, we use the treatment feature as an
instrumental variable. To do this, we define the potential outcome as a function of the perceived treatment
28
feature, and the treatment and confounding features. Formally, we replace Assumption 5 with the following
assumption while maintaining the same separability between the treatment feature and the confounding
features.
ASSUMPTION 9 (SEPARABILITY WITH THE PERCEIVED TREATMENT FEATURE) The potential outcome
is a function of the perceived treatment T˜
i
, the treatment features of interest Ti
, and the confounding features
Ui
. That is, for any given x ∈ X and all i, we have:
Yi(x) = Yi(Tei(gT (x), gU (x)), gT (x), gU (x))
where Tei(gT (x), gU (x)) ∈ {0, 1} is the perceived treatment feature, gT (x) ∈ {0, 1}, and gU (x) ∈ U. In
addition, gT and gU are separable in the same sense as Assumption 5.
Lastly, we adopt the standard instrumental variable assumptions in current settings (Imbens and Angrist,
1994). First, we assume monotonicity; the existence of treatment feature makes it no less likely for a
respondent to perceive it as such. Second, we assume an exclusion restriction; the treatment feature only
affects the outcome through the perceived treatment feature. Both assumptions are made while keeping the
confounding features constant. We formally state these assumptions here.
ASSUMPTION 10 (VALIDITY OF THE INSTRUMENTAL VARIABLE) We make the following instrumental
variable assumptions:
(a) (Monotonicity) For any u ∈ U, we have:
Tei(1,u) ≥ Tei(0,u) and P(Tei(1,u) = 1) > P(Tei(0,u) = 1).
(b) (Exclusion Restriction) For any t˜∈ {0, 1}, u ∈ U, and i = 1, 2, . . . , n, we have:
Yi(t,˜ 1,u) = Yi(t,˜ 0,u) = Yi(t,˜ u).
In many practical settings, the monotonicity assumption is reasonable. In our application, for example, if
there is no military background in a candidate biography, a respondent should not notice the presence of this
treatment feature. Exclusion restriction, however, may not be credible in some cases because it is possible
for a respondent to be influenced by the treatment feature without noticing it.
Under this setup, we are interested in estimating the local average treatment effect (LATE) of the perceived treatment feature among the respondents who notice the presence of the treatment feature only when
the treatment object actually contains such a feature. We define this LATE as follows:
β := E[Yi(1, Ui) − Yi(0, Ui) | Tei(1, Ui) = 1, Tei(0, Ui) = 0], (S1)
where the first input of the potential outcome is the perceived treatment feature instead of the treatment
feature, i.e., Yi(Tei = t,˜ Ui = u).
29
P R hγ(R) X
T = gT (X) Te
U = gU (X)
Y
Deep generative model
Figure S1: Directed Acyclic Graph (DAG) of the Assumed Data Generating Process with the Perceived
Treatment Feature. This DAG is identical to that of Figure 1 except that the perceived treatment feature Te is
added. The perceived treatment feature may be affected by the treatment feature T and/or the confounding
features U. There may also be unobserved confounding variables that affect both the perceived treatment
feature and the outcome Y . An arrow with red double lines represents a deterministic causal relation while
an arrow with a single line indicates a possibly stochastic relationship.
S3.2 Nonparametric identification
We extend our nonparametric identification result obtained in Section 3.2 to the instrumental variable setting. Figure S1 summarizes the assumed data generation process with the perceived treatment feature.
The absence of direct arrow from the treatment feature T into Y encodes exclusion restriction (Assumption 10(b)). In addition, we allow for the possible existence of unobserved confounders between the perceived treatment feature and the outcome, indicated by the dotted line in the DAG.
The following theorem establishes the nonparametric identification of the LATE defined in Equation (S1).
As in the case of ATE (see Theorem 1), identification is achieved by adjusting for the deconfounder f(Ri)
and using the treatment feature Ti as an instrument for the perceived treatment feature. Similarly to the ATE
case, the deconfounder satisfies the conditional independence relation {Yi
, Tei}⊥⊥Ri
| Ti = t, f(Ri). The
difference is that the inner representation Ri
is now independent of the perceived treatment feature as well
as the outcome after conditioning on the treatment feature and the deconfounder. Finally, we emphasize
that like Theorem 1, this result does not require the deconfounder to be unique.
THEOREM 3 (NONPARAMETRIC IDENTIFICATION OF THE LATE) Under Assumptions 1–4, 6, 8–10, there
exists a deconfounder function f : R → Q with dQ = dim(Q) ≤ dR = dim(R) that satisfies the following
conditional independence relation:
{Yi
, Tei}⊥⊥Ri
| Ti = t, f(Ri) = q,
for all q ∈ Q and t = 0, 1. In addition, the treatment feature and the deconfounder are separable. Then,
by adjusting for such a deconfounder, we can uniquely and nonparametrically identify the local average
treatment effect (LATE) defined in Equation (S1) as:
β =
R
R
E[Yi
| Ti = 1, f(Ri)] − E[Yi
| Ti = 0, f(Ri)]dF(Ri)
R
R
E[Tei
| Ti = 1, f(Ri)] − E[Tei
| Ti = 0, f(Ri)]dF(Ri)
.
The proof is given in Appendix S4.4.
30
R f(R;λ)
µ1(f(R;λ); θ1)
µ0(f(R;λ); θ0)
m1(f(R;λ); ζ1)
m0(f(R;λ); ζ0)
Yi
| Ti = 1
Yi
| Ti = 0
Tei
| Ti = 1
Tei
| Ti = 0
Figure S2: Diagram Illustrating the Proposed Model Architecture with the Instrumental Variable. The
proposed model takes an internal representation of a treatment object Ri as an input, and finds a deconfounder f(Ri), which is a lower-dimensional representation of Ri
, and then use it to predict the conditional expectations of the outcome µt(f(Ri)) := E[Yi
| Ti = t, f(Ri)] and the perceived treatment feature
mt(f(Ri)) := E[Tei
| Ti = t, f(Ri)] under each treatment arm t.
S3.3 Estimation and inference
Next, we extend the estimation and inference approaches developed in Section 3.3 to the instrumental variable setting. The main difference is that we additionally model the conditional expectation of the perceived
treatment feature given the treatment feature and deconfounder,
mt(f(Ri)) := E[Tei
| Ti = t, f(Ri)],
for t ∈ {0, 1}. Figure S2 presents the proposed neural network architecture that extends the diagram shown
in Figure 2 to the instrumental variable setting. The loss function is given by,
{λˆ, θˆ,
ˆζ} = argmin
λ,θ,ζ
1
n
Xn
i=1

(Yi − µTi
(f(Ri
;λ); θTi
))2 +

Tei − mTi
(f(Ri
;λ); ζTi
)
2

(S2)
Given this neural network architecture, we again use the DML framework for estimation and inference.
The exact estimation procedure is described here for completeness.
1. Randomly partition the data into K folds of equal size where the size of each fold is n = N/K. The
observation index is denoted by I(i) ∈ {1, . . . , K} where I(i) = k implies that the ith observation
belongs to the kth fold.
2. For each fold k ∈ {1, · · · , K}, use observations with I(i) ̸= k as training data:
(a) split the training data into two folds, I
(−k)
1
and I
(−k)
2
(b) obtain estimates of deconfounder and the conditional outcome function on the first fold, denoted
by
fˆ(−k)
({Ri}
i∈I
(−k)
1
) := f({Ri}
i∈I
(−k)
1
;λˆ(−k)
),
µ
(−k)
t
:= µt(fˆ({Ri}
i∈I
(−k)
1
;λ
(−k)
); θˆ(−k)
),
31
and that of the perceived treatment feature, denoted by
mˆ
(−k)
t
({Ri}
i∈I
(−k)
1
) := mt(f({Ri}
i∈I
(−k)
1
;λˆ(−k)
); ˆζ
(−k)
)
by solving the optimization problem given in Equation (S2), and
(c) obtain an estimate of the propensity score given the estimated deconfounder on the second fold,
denoted by πˆ
(−k)
(fˆ(−k)
({Ri}
i∈I
(−k)
2
)) := ˆπ
(−k)
(f({Ri}
i∈I
(−k)
2
;λˆ(−k)
)).
3. Compute an LATE estimate βˆ as a solution to:
1
nK
X
K
k=1
X
i:I(i)=k
ϕ(Dei
; β, ˆ fˆ(−k)
, µˆ
(−k)
1
, µˆ
(−k)
0
, mˆ
(−k)
1
, mˆ
(−k)
0
, πˆ
(−k)
) = 0,
where Dei
:= {Yi
, Tei
, Ti
, Ri} and
ϕ(Dei
; β, f, µ1, µ0, m1, m0, π)
=
Ti{Yi − µ1(f(Ri))}
π(f(Ri)
−
(1 − Ti){Yi − µ0(f(Ri))}
1 − π(f(Ri)) + µ1(f(Ri)) − µ0(f(Ri))
−
"
Ti{Tei − m1(f(Ri))}
π(f(Ri)) −
(1 − Ti){Tei − m0(f(Ri))}
1 − π(f(Ri)) + m1(f(Ri)) − m0(f(Ri))#
· β.
Similar to the ATE case, we can establish the asymptotic property of this estimator. We first outline a
set of additional regularity conditions required beyond Assumption 7.
ASSUMPTION 11 (ADDITIONAL REGULARITY CONDITIONS) Let c1, c2, and q > 2 be positive constants
and δn be a sequence of positive constants approaching zero as the sample size n increases. Then, the
following conditions hold:
(a) (Primitive condition)
E


(Yi − µTi
(f(Ri))) − β ·

Tei − mTi
(f(Ri))


2
1/2
≥ c2
(b) (Perceived treatment model estimation)
E[m1(f(Ri)) − m0(f(Ri))] ≥ c2, E[|mˆ Ti
(fˆ(Ri)) − mTi
(f(Ri))|
q
]
1/q ≤ c1,
E[|mˆ Ti
(fˆ(Ri)) − mTi
(f(Ri))|
2
]
1/2 ≤ δnn
−1/4
.
Together with Assumption 7, these regularity conditions are essentially equivalent to the assumptions required for DML inference on LATE (Chernozhukov et al., 2018).
Under the above assumptions, the asymptotic normality of the proposed estimator can be established.
THEOREM 4 (ASYMPTOTIC NORMALITY OF INSTRUMENT VARIABLE ESTIMATOR) Under Assumptions 1–
4, 6–11, the estimator βˆ obtained from the influence function ϕ satisfies asymptotic normality:
√
n(βˆ − β)
σ
d−→ N (0, 1)
where σ
2 = E[ϕ(Dei
; β, f, µ1, µ0, m1, m0, π)
2
]/E[γ1(f(Ri)) − γ0(f(Ri))]2
.
32
Proof is omitted given that, like Theorem 2, the result follows immediately from the application of DML
theory (Chernozhukov et al., 2018).
S4 Proofs
S4.1 Proof of Lemma 1
We use proof by contradiction. Suppose that the overlap condition is not satisfied. That is, there exist
t ∈ {0, 1} and u ∈ U such that P(Ti = t | Ui = u) = 0. This implies that under Assumptions 3 and 4,
there exist a deterministic function g˜T : U → {0, 1} and some x ∈ X such that t = ˜gT (u) = ˜gT (gU (x)).
This contradicts Assumption 5. ✷
S4.2 Proof of Theorem 1
Under a deep generative model of Definition 1, the distribution of Xi only depends on Pi
, and hence we
have Yi(x)⊥⊥Xi
| Pi
. Together with Assumption 2, Lemma 4.3 of Dawid (1979) implies Yi(x)⊥⊥Xi
.
Then, under Assumptions 3 and 5, we have:
Yi(t, Ui)⊥⊥Ti
| Ui
. (S3)
Next, under Assumptions 3, 4, and 6, Ui
is a deterministic function of Ri such that we can write Ui =
f
∗
(Ri) for some function f
∗
: R → U. Furthermore, Assumption 5 implies Yi⊥⊥Ri
| Ti = t, f
∗
(Ri) = u
and 0 < Pr(Ti = t | f
∗
(Ri) = u) < 1 for all t ∈ {0, 1} and u ∈ U. Thus, we have:
P(Yi(t, Ui) = y) = Z
U
P(Yi(t, Ui) = y | Ui)dF(Ui)
=
Z
U
P(Yi(t, Ui) = y | Ti = t, Ui)dF(Ui)
=
Z
U
P(Yi = y | Ti = t, f
∗
(Ri))dF(f
∗
(Ri)),
=
Z
R
P(Yi = y | Ti = t, f
∗
(Ri))dF(Ri),
where the second equality follows from Equation (S3) and Lemma 1, and the third equality is due to Assumption 1. Finally, suppose there is another function f : R → Q, which satisfies the conditional independence relation Yi⊥⊥Ri
| Ti = t, f(Ri) = q for all q ∈ Q and is separable from the treatment feature.
Then,
Z
R
P(Yi = y | Ti = t, f(Ri))dF(Ri) = Z
R
P(Yi = y | Ti = t, f(Ri), Ri)dF(Ri)
=
Z
R
P(Yi = y | Ti = t, f
∗
(Ri), Ri)dF(Ri)
=
Z
R
P(Yi = y | Ti = t, f
∗
(Ri))dF(Ri)
33
Thus, any function of Ri
that satisfies this conditional independence relation leads to the same identification
formula for the marginal distribution of potential outcome. ✷
S4.3 Proof of Theorem 2
Assumptions 7(c)–(d) and the triangule inequality imply,
E[|πˆ(fˆ(Ri)) − π(f(Ri))|
q
]
1/q = E[|{πˆ(fˆ(Ri)) − πˆ(f(Ri))} + {πˆ(f(Ri)) − π(f(Ri))}|q
]
1/q
≤ E[|πˆ(fˆ(Ri)) − πˆ(f(Ri))|
q
]
1/q + c1
≤ L · E
h

fˆ(Ri) − f(Ri)



q
i1/q
+ c1
= (L + 1)c1 (S4)
where L is a Lipschitz constant. Similarly, we can also show,
E



πˆ(fˆ(Ri)) − π(f(Ri))



2
1/2
≤ L · E


fˆ(Ri) − f(Ri)



2
1/2
+ E
h
|πˆ(f(Ri)) − π(f(Ri))|
2
i1/2
≤ (L + 1)δnn
−1/4
. (S5)
Together with Assumption 7(b), Equation (S5) implies that there exists a sequence of positive constants δ
′
n
converging to zero as the sample size n increases such that the following inequality holds,
E[|πˆ(fˆ(Ri)) − π(f(Ri))|
2
]
1/2
· E[|µˆTi
(fˆ(Ri)) − µTi
(f(Ri))|
2
]
1/2 ≤ δ
′
nn
−1/2
. (S6)
Thus, the standard regularity conditions of the DML theory (Chernozhukov et al., 2018) are satisfied for the
estimated propensity score with the estimated deconfounder, i.e., πˆ(fˆ(Ri)). Finally, Assumptions 7(a)–(b)
and Equations (S4) and (S6) imply,
√
n (ˆτ − τ )
d−→ N (0, σ2
)
where σ
2 = E[ψ(Di
; τ, f, η1, η0, π)
2
].
✷
S4.4 Proof of Theorem 3
Under a deep generative model (Definition 1), the distribution of Xi only depends on Pi
, and hence
we have {Yi(x), Tei(x)}⊥⊥Xi
| Pi
. Together with Assumption 2, Lemma 4.3 of Dawid (1979) implies
{Yi(x), Tei(x)}⊥⊥Xi
. Under Assumptions 3, 4, 8, 9, and 10 (b), we have, for any t,t˜∈ {0, 1} and u ∈ U:
{Yi(t,˜ u), Tei(t,u)}⊥⊥{Ti
, Ui}. (S7)
34
Then, for any u ∈ U,
E[Yi
| Ti = 1, Ui = u] − E[Yi
| Ti = 0, Ui = u]
= E[Yi(Tei(1,u),u) | Ti = 1, Ui = u] − E[Yi(Tei(0,u),u) | Ti = 0, Ui = u]
= E[Yi(Tei(1,u),u) − Yi(Tei(0,u),u)]
= E[Yi(Tei(1,u),u) − Yi(Tei(0,u),u) | Tei(1,u) = 1, Tei(0,u) = 0] · P(Tei(1,u) = 1, Tei(0,u) = 0)
= E[Yi(1,u) − Yi(0,u) | Tei(1,u) = 1, Tei(0,u) = 0] · P(Tei(1,u) = 1, Tei(0,u) = 0),
where the second equality follows from Equation (S7), the third equality is due to Assumption 10. We also
have:
P(Tei(1,u) = 1, Tei(0,u) = 0) = E[Tei(1,u) − Tei(0,u)]
= E[Tei(1,u) | Ti = 1, Ui = u] − E[Tei(0,u) | Ti = 0, Ui = u]
= E[Tei
| Ti = 1, Ui = u] − E[Tei
| Ti = 1, Ui = u]
where the second equality follows from Equation (S7). Together, under Assumption 10 (a), we have:
E[Yi(1,u) − Yi(0,u) | Tei(1,u) = 1, Tei(0,u) = 0]
=
E[Yi
| Ti = 1, Ui = u] − E[Yi
| Ti = 0, Ui = u]
E[Tei
| Ti = 1, Ui = u] − E[Tei
| Ti = 1, Ui = u]
. (S8)
Finally, the LATE is identified as:
E[Yi(1, Ui) − Yi(0, Ui) | Tei(1, Ui) = 1, Tei(0, Ui) = 0]
=
Z
U
E[Yi(1, Ui) − Yi(0, Ui) | Tei(1, Ui) = 1, Tei(0, Ui) = 0, Ui
]dF(Ui
| Tei(1, Ui) = 1, Tei(0, Ui) = 0)
=
Z
U
E[Yi
| Ti = 1, Ui
] − E[Yi
| Ti = 0, Ui
]
E[Tei
| Ti = 1, Ui
] − E[Tei
| Ti = 1, Ui
]
dF(Ui
| Tei(1, Ui) > Tei(0, Ui))
=
Z
U
E[Yi
| Ti = 1, Ui
] − E[Yi
| Ti = 0, Ui
]
E[Tei
| Ti = 1, Ui
] − E[T˜
i
| Ti = 1, Ui
]
·
P(Tei(1, Ui) = 1, Tei(0, Ui) = 0 | Ui)
P(Tei(1, Ui) = 1, Tei(0, Ui) = 0)
dF(Ui)
=
Z
U
E[Yi
| Ti = 1, Ui
] − E[Yi
| Ti = 0, Ui
]
E[Tei
| Ti = 1, Ui
] − E[Tei
| Ti = 1, Ui
]
·
E[Tei
| Ti = 1, Ui
] − E[Tei
| Ti = 1, Ui
]
P(Tei(1, Ui) = 1, Tei(0, Ui) = 0)
dF(Ui)
=
R
U
E[Yi
| Ti = 1, Ui
] − E[Yi
| Ti = 0, Ui
]dF(Ui)
R
U
E[Tei
| Ti = 1, Ui
] − E[Tei
| Ti = 0, Ui
]dF(Ui)
=
R
R
E[Yi
| Ti = 1, f(Ri)] − E[Yi
| Ti = 0, f(Ri)]dF(Ri)
R
R
E[Tei
| Ti = 1, f(Ri)] − E[Tei
| Ti = 0, f(Ri)]dF(Ri)
where the second equality follows from Equation (S8), the third equality is due to Bayes’ theorem, and the
last equality (as well as the existence of deconfounder) follows from the same argument used to establish
Theorem 1. ✷
35
S5 Results of Additional Simulation Studies
95% confidence interval Runtime
Bias RMSE coverage avg. length (seconds)
Weak confounding w/ separability
Proposed estimator (new) −0.33 1.06 0.94 3.47 42.1
Proposed estimator (reuse) −0.26 0.98 0.92 2.95 54.1
Difference-in-Means 3.61 3.61 0 4.72 0.0
Outcome model with BERT 1.17 1.00 0.12 0.53 296
DML with BERT 0.58 4.21 0.93 2.10 327
Moderate confounding w/ separability
Proposed estimator (new) −1.07 2.72 0.95 9.00 43.6
Proposed estimator (reuse) −1.05 2.36 0.93 6.85 62.9
Difference-in-Means 7.95 7.95 0 9.50 0.0
Outcome model with BERT 3.44 2.27 0.05 0.92 673
DML with BERT 2.09 18.3 0.92 5.14 720
Strong confounding w/ separability
Proposed estimator (new) −14.6 36.9 0.88 113 55.3
Proposed estimator (reuse) −15.1 36.0 0.92 96.3 74.3
Difference-in-Means 86.0 86.0 0 95.7 0.0
Outcome model with BERT 112 114 0 13.2 2731
DML with BERT 208 917 0.26 382 2756
Weak confounding w/o separability
Proposed estimator (new) 3.23 3.27 0 1.45 35.9
Proposed estimator (reuse) 2.87 2.89 0 1.34 41.1
Difference-in-Means 2.20 2.20 0.03 4.03 0.0
Outcome model with BERT 2.55 2.70 0.01 1.02 320
DML with BERT 6.18 16.7 0.05 4.69 348
Moderate confounding w/o separability
Proposed estimator (new) 6.70 6.76 0 2.89 42.5
Proposed estimator (reuse) 5.90 5.93 0 2.66 44.9
Difference-in-Means 4.39 4.40 0 8.04 0.0
Outcome model with BERT 7.56 7.66 0 1.85 624
DML with BERT 12.1 30.5 0.06 10.1 656
Strong confounding w/o separability
Proposed estimator (new) 76.3 76.7 0 29.8 53.0
Proposed estimator (reuse) 66.8 67.1 0 27.7 56.4
Difference-in-Means 44.0 44.0 0 80.3 0.0
Outcome model with BERT 116 117 0 13.2 2689
DML with BERT 207 814 0.26 425 2716
Table S5: Simulation Results with 200 Monte Carlo trials
36
95% confidence interval Average
Bias RMSE coverage avg. length time (sec.)
Weak confounding w/ separability
Proposed estimator (new) −0.31 1.09 0.93 3.55 43.0
Proposed estimator (reuse) −0.21 0.96 0.93 2.90 55.7
Moderate confounding w/ separability
Proposed estimator (new) −0.99 2.77 0.92 8.83 45.7
Proposed estimator (reuse) −1.00 2.67 0.90 6.99 61.7
Strong confounding w/ separability
Proposed estimator (new) −14.3 36.1 0.89 108 57.7
Proposed estimator (reuse) −16.0 38.1 0.90 98.8 76.3
Table S6: Simulation Results based on 1000 Monte Carlo trials
S6 Additional Empirical Application: Hong Kong Experiment
To further validate the proposed GPI methodology, we apply it to the Hong Kong experiment conducted
by Fong and Grimmer (2023). This experiment examines the extent to which U.S. commitments to Hong
Kong influence public perceptions of U.S. government support for Hong Kong protesters. To investigate
this question, the authors carried out two experiments—one in December 2019 (N = 1,983) and another
in October 2020 (N = 2,072). For each experiment, they first generated 555,660 unique candidate texts
by randomly varying several text features: descriptions of commitments (commitments the United States
made to Hong Kong), bravery (the bravery displayed by the protesters), mistreatment (China’s mistreatment
of its own citizens), flags (whether protesters were shown waving American flags), threat (the security
threat China poses to the United States), economy (information about Hong Kong’s political system and
economy), and violations (how China’s actions violate its treaty with the United Kingdom).
To mitigate confounding bias arising from these text features, the authors created roughly 15 variants of
texts for each feature, randomly concatenated two or three variants to form a complete text, and then randomly assigned the resulting texts to participants. Participants read a text and then rated, on a 0–100 scale,
how strongly they agreed with the view that the U.S. government should support Hong Kong protesters.
Because textual features are randomized, the authors regressed participants’ responses on the seven text
features using ordinary least squares (OLS).
We estimate the average treatment effect separately for each experimental wave. Following the empirical
application in Section 5, we use the GPI methodology based on the text-reuse approach with Llama 3-
8B. After extracting the internal representation, we apply the proposed estimation procedure described in
Section 3, using five-fold cross-fitting. We adopt a larger fold size than in Section 5 to ensure that the
neural network is trained on a sufficiently large number of samples. For comparison—consistent with our
37
Methods ATE Estimates 95% Confidence Interval IOSS Runtime (sec.)
Wave 1: December 2019
OLS (original) 5.231 [1.814, 8.648] - 0.0
GPI (reuse) 6.175 [2.784, 9.566] 0.04 35.9
Outcome model with BERT 26.591 [25.482, 27.701] 0.28 11890.6
DML with BERT 24.361 [20.163, 28.560] 11892.9
Wave 2: October 2020
OLS (original) 2.680 [0.269, 5.091] - 0.0
GPI (reuse) 2.043 [-0.790, 4.877] 0.04 27.9
Outcome model with BERT 1.676 [1.319, 2.033] 0.07 9940.0
DML with BERT 2.808 [−0.519, 6.136] 9942.7
Table S7: The Estimated Average Treatment Effect (ATE) for the Hong Kong Experiment.
simulation studies in Section 4 and the empirical application in Section 5—we also implement two existing
BERT-based methods: the outcome-model approach with BERT (Pryzant et al., 2021) and DML with BERT
(Gui and Veitch, 2023). Finally, we replicate the original OLS analysis. In this application, the experimental
design should effectively mitigate confounding bias, so OLS serves as a reasonable approximation to the
ground truth.
Table S7 presents the estimated ATEs for both experimental waves. The GPI estimates are consistent
with the original OLS estimates that controls the textual features directly. We find that IOSS for the GPI
method is close to 0 (0.04 for both waves), indicating that the deconfounder extracted by GPI is disentangled
from the treatment feature. In contrast, the BERT-based methods yield significantly larger ATE estimates
for Wave 1 that significantly diverge from the OLS estimates. This unually large estiamte corresponds to
a large value of IOSS for Wave 1, which is 0.28 (the IQSS score for Wave 2 is smaller, equaling 0.07).
Moreover, the GPI method is computationally efficient, with runtimes significantly faster than those of the
BERT-based methods.
38
